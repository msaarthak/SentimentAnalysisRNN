{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentanal.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-8yg9DvTmce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGwnrmfSTrn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIT1GROATvFw",
        "colab_type": "code",
        "outputId": "a73270a5-f7a5-44f7-924d-840695585389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_874Lo5TzUS",
        "colab_type": "code",
        "outputId": "b8280025-84ef-4836-8e0f-fb65f3345139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5isfTF6T3K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga-lit1DT_ce",
        "colab_type": "code",
        "outputId": "4247152d-94c1-4006-a3ed-4e9ebfdba2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "imdb.maybe_download_and_extract()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiemxMsDUSUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_text, y_train = imdb.load_data(train=True)\n",
        "x_test_text, y_test = imdb.load_data(train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwzEu3cjUYvQ",
        "colab_type": "code",
        "outputId": "e0f939b6-a68f-4784-9180-ac2511e6e593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Train-set size: \", len(x_train_text))\n",
        "print(\"Test-set size:  \", len(x_test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-set size:  25000\n",
            "Test-set size:   25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEwUAZ0RUdk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_text = x_train_text + x_test_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u30_aQPoUkSI",
        "colab_type": "code",
        "outputId": "17d5a285-35e1-48a9-861e-87196c4d746a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "x_train_text[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"If you cannot enjoy a chick flick, stop right now. If, however, you enjoy films that illustrate complex characters and provide extraordinary acting, read on.<br /><br />Ann Grant Lord is dying. Her two daughters arrive to be at her bedside. Ann begins talking about people from her past of whom the daughters are unaware, and they question as to whether these lost acquaintances are real or imagined. They come to realize that these people from their mother's past are, indeed, real.<br /><br />The story shifts, basically, between 1953 and circa 2000 with a few glimpses at Ann's life between those years. It was in 1953 that Ann met the love of her life and experienced her life's greatest tragedy.<br /><br />One of Ann's two best friends from college, Lila, is being married. Ann's other best friend is Lila's brother, Buddy. Lila and Buddy are the children of a rich Newport family, whereas Ann is a cabaret singer living in Greenwich Village who wants to be a free spirit but is still bound by many of those 1950's conventions.<br /><br />Soon after Ann arrives to be maid of honor at Lila's wedding, she meets the person who will become the pivotal character in the lives of the three - Harris. He is the adult son of a former servant of the family who grew up with Lila and Buddy and has gone on to become a physician in a small New England town. Ann immediately becomes enamored of Harris which adds a complication to the fact that Lila has always been in love with Harris and continues to be. Buddy, also, is in love with Harris, but being 1953, he has redirected that homosexual desire for Harris to his good friend, Ann for he cannot admit to himself that he has a sexual craving for another man. Buddy exhibits his inner frustration outwardly by being the alcoholic, wise-cracking bad boy of the family - much to the chagrin of his very proper and uptight parents.<br /><br />Needless to say, all of these expressed and repressed emotions lead to tragedy - after all this is a chick flick.<br /><br />In the present time, Ann's daughters have become distant from their mother and are suffering their own life realizations and doubts. Constance is working to emotional exhaustion trying to keep up her roll as perfect mother and wife. Nina, having always felt inferior, cannot maintain a relationship.<br /><br />Stir all of these relationships into a span of fifty years, and you get an intriguing look at society, its values, and its effects upon the personalities and actions of the complex people involved.<br /><br />All of the acting in Evening is excellent, but there are some extraordinary performances and scenes - along with two unique family relationships - that make this film so very, very special.<br /><br />Claire Danes plays the 1950's Ann, and she does it in a style that clearly shows an intelligent woman of those times who is conflicted by what she is supposed to do as opposed to what she wants to do. Her performance is not easily forgettable.<br /><br />Vanessa Redgrave plays the dying Ann whose mind shifts from the present, to the past, to flights of fantasy, and of course, Redgrave pulls it all off with sterling style.<br /><br />Natasha Richardson - Redgrave's real daughter - plays Ann's daughter, Constance, in the film. The scenes between this real life mother and daughter playing fictional mother and daughter are an insightful treat to watch.<br /><br />Toni Collette plays Ann's other daughter, Nina. Nina spends a good deal of her time being depressed and feeling sorry for herself while shutting out a good man who loves her as well as her mother and sister. Collette is perfect for a part such as this, but I have never seen her give a bad or unbelievable performance no matter what part she plays.<br /><br />Mamie Gummer plays 1950's Lila and shows us a woman even more conflicted of her expected role in life than her good friend, Ann. She is very good.<br /><br />Meryl Streep - Gummer's mother - plays present day Lila. What is there to say about Meryl Streep other than she always gives an insightful and rewarding performance.<br /><br />Director Lajos Koltai states in the DVD extras that he sought out Glenn Close to play the relatively small part of Lila's mother because he felt she was the only actress he could think of to play one scene in the film. He certainly was right, and Close's performance in that one scene etches it in your mind. All the other scenes in which Close is Lila's very proper mother, and you get another performance to treasure.<br /><br />There are three other scenes in the film, combined with the one featuring Close described above, that make the whole movie worth watching. On Lila's wedding day, Ann comes into her room and crawls into to bed with her friend to discuss Lila's misforgivings about her upcoming wedding to a man she clearly does not love. This scene is repeated fifty years later when Lila comes and crawls into bed with her dying friend Ann to talk about the lives they have lived. In this latter scene, Streep and Redgrave are enthralling.<br /><br />The other memorable scene - at least to me - is when Buddy declares his love for Ann. Hugh Dancy as Buddy gives us a heartbreaking performance of a young man torn apart by his conflicting sexual feelings. His performance is superior.<br /><br />Chick flick? Yes. A very special film with unbelievable acting, directing, and scenery? Definitely. I cannot recommend Evening too much.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upVK7HNuUqGF",
        "colab_type": "code",
        "outputId": "a1c0e080-3a29-452f-df59-e414bfb98fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_dsDCoMUwwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GNj1fkLU339",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwV7auU4U9fe",
        "colab_type": "code",
        "outputId": "b3df2592-1095-4942-ebe8-ac613857bfd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "tokenizer.fit_on_texts(data_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.7 s, sys: 94.1 ms, total: 11.8 s\n",
            "Wall time: 11.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_gEgR8dVFlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if num_words is None:\n",
        "    num_words = len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5vtzuo1VOYp",
        "colab_type": "code",
        "outputId": "b90f7b6c-0fae-45da-e421-e263afe25a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'a': 3,\n",
              " 'of': 4,\n",
              " 'to': 5,\n",
              " 'is': 6,\n",
              " 'br': 7,\n",
              " 'in': 8,\n",
              " 'it': 9,\n",
              " 'i': 10,\n",
              " 'this': 11,\n",
              " 'that': 12,\n",
              " 'was': 13,\n",
              " 'as': 14,\n",
              " 'for': 15,\n",
              " 'with': 16,\n",
              " 'movie': 17,\n",
              " 'but': 18,\n",
              " 'film': 19,\n",
              " 'on': 20,\n",
              " 'not': 21,\n",
              " 'you': 22,\n",
              " 'are': 23,\n",
              " 'his': 24,\n",
              " 'have': 25,\n",
              " 'be': 26,\n",
              " 'one': 27,\n",
              " 'he': 28,\n",
              " 'all': 29,\n",
              " 'at': 30,\n",
              " 'by': 31,\n",
              " 'an': 32,\n",
              " 'they': 33,\n",
              " 'so': 34,\n",
              " 'who': 35,\n",
              " 'from': 36,\n",
              " 'like': 37,\n",
              " 'or': 38,\n",
              " 'just': 39,\n",
              " 'her': 40,\n",
              " 'out': 41,\n",
              " 'about': 42,\n",
              " 'if': 43,\n",
              " \"it's\": 44,\n",
              " 'has': 45,\n",
              " 'there': 46,\n",
              " 'some': 47,\n",
              " 'what': 48,\n",
              " 'good': 49,\n",
              " 'when': 50,\n",
              " 'more': 51,\n",
              " 'very': 52,\n",
              " 'up': 53,\n",
              " 'no': 54,\n",
              " 'time': 55,\n",
              " 'my': 56,\n",
              " 'even': 57,\n",
              " 'would': 58,\n",
              " 'she': 59,\n",
              " 'which': 60,\n",
              " 'only': 61,\n",
              " 'really': 62,\n",
              " 'see': 63,\n",
              " 'story': 64,\n",
              " 'their': 65,\n",
              " 'had': 66,\n",
              " 'can': 67,\n",
              " 'me': 68,\n",
              " 'well': 69,\n",
              " 'were': 70,\n",
              " 'than': 71,\n",
              " 'much': 72,\n",
              " 'we': 73,\n",
              " 'bad': 74,\n",
              " 'been': 75,\n",
              " 'get': 76,\n",
              " 'do': 77,\n",
              " 'great': 78,\n",
              " 'other': 79,\n",
              " 'will': 80,\n",
              " 'also': 81,\n",
              " 'into': 82,\n",
              " 'people': 83,\n",
              " 'because': 84,\n",
              " 'how': 85,\n",
              " 'first': 86,\n",
              " 'him': 87,\n",
              " 'most': 88,\n",
              " \"don't\": 89,\n",
              " 'made': 90,\n",
              " 'then': 91,\n",
              " 'its': 92,\n",
              " 'them': 93,\n",
              " 'make': 94,\n",
              " 'way': 95,\n",
              " 'too': 96,\n",
              " 'movies': 97,\n",
              " 'could': 98,\n",
              " 'any': 99,\n",
              " 'after': 100,\n",
              " 'think': 101,\n",
              " 'characters': 102,\n",
              " 'watch': 103,\n",
              " 'films': 104,\n",
              " 'two': 105,\n",
              " 'many': 106,\n",
              " 'seen': 107,\n",
              " 'character': 108,\n",
              " 'being': 109,\n",
              " 'never': 110,\n",
              " 'plot': 111,\n",
              " 'love': 112,\n",
              " 'acting': 113,\n",
              " 'life': 114,\n",
              " 'did': 115,\n",
              " 'best': 116,\n",
              " 'where': 117,\n",
              " 'know': 118,\n",
              " 'show': 119,\n",
              " 'little': 120,\n",
              " 'over': 121,\n",
              " 'off': 122,\n",
              " 'ever': 123,\n",
              " 'does': 124,\n",
              " 'your': 125,\n",
              " 'better': 126,\n",
              " 'end': 127,\n",
              " 'man': 128,\n",
              " 'scene': 129,\n",
              " 'still': 130,\n",
              " 'say': 131,\n",
              " 'these': 132,\n",
              " 'here': 133,\n",
              " 'scenes': 134,\n",
              " 'why': 135,\n",
              " 'while': 136,\n",
              " 'something': 137,\n",
              " 'such': 138,\n",
              " 'go': 139,\n",
              " 'through': 140,\n",
              " 'back': 141,\n",
              " 'should': 142,\n",
              " 'those': 143,\n",
              " 'real': 144,\n",
              " \"i'm\": 145,\n",
              " 'now': 146,\n",
              " 'watching': 147,\n",
              " 'thing': 148,\n",
              " \"doesn't\": 149,\n",
              " 'actors': 150,\n",
              " 'though': 151,\n",
              " 'funny': 152,\n",
              " 'years': 153,\n",
              " \"didn't\": 154,\n",
              " 'old': 155,\n",
              " 'another': 156,\n",
              " '10': 157,\n",
              " 'work': 158,\n",
              " 'before': 159,\n",
              " 'actually': 160,\n",
              " 'nothing': 161,\n",
              " 'makes': 162,\n",
              " 'look': 163,\n",
              " 'director': 164,\n",
              " 'find': 165,\n",
              " 'going': 166,\n",
              " 'same': 167,\n",
              " 'new': 168,\n",
              " 'lot': 169,\n",
              " 'every': 170,\n",
              " 'few': 171,\n",
              " 'again': 172,\n",
              " 'part': 173,\n",
              " 'cast': 174,\n",
              " 'down': 175,\n",
              " 'us': 176,\n",
              " 'things': 177,\n",
              " 'want': 178,\n",
              " 'quite': 179,\n",
              " 'pretty': 180,\n",
              " 'world': 181,\n",
              " 'horror': 182,\n",
              " 'around': 183,\n",
              " 'seems': 184,\n",
              " \"can't\": 185,\n",
              " 'young': 186,\n",
              " 'take': 187,\n",
              " 'however': 188,\n",
              " 'got': 189,\n",
              " 'thought': 190,\n",
              " 'big': 191,\n",
              " 'fact': 192,\n",
              " 'enough': 193,\n",
              " 'long': 194,\n",
              " 'both': 195,\n",
              " \"that's\": 196,\n",
              " 'give': 197,\n",
              " \"i've\": 198,\n",
              " 'own': 199,\n",
              " 'may': 200,\n",
              " 'between': 201,\n",
              " 'comedy': 202,\n",
              " 'right': 203,\n",
              " 'series': 204,\n",
              " 'action': 205,\n",
              " 'must': 206,\n",
              " 'music': 207,\n",
              " 'without': 208,\n",
              " 'times': 209,\n",
              " 'saw': 210,\n",
              " 'always': 211,\n",
              " 'original': 212,\n",
              " \"isn't\": 213,\n",
              " 'role': 214,\n",
              " 'come': 215,\n",
              " 'almost': 216,\n",
              " 'gets': 217,\n",
              " 'interesting': 218,\n",
              " 'guy': 219,\n",
              " 'point': 220,\n",
              " 'done': 221,\n",
              " \"there's\": 222,\n",
              " 'whole': 223,\n",
              " 'least': 224,\n",
              " 'far': 225,\n",
              " 'bit': 226,\n",
              " 'script': 227,\n",
              " 'minutes': 228,\n",
              " 'feel': 229,\n",
              " '2': 230,\n",
              " 'anything': 231,\n",
              " 'making': 232,\n",
              " 'might': 233,\n",
              " 'since': 234,\n",
              " 'am': 235,\n",
              " 'family': 236,\n",
              " \"he's\": 237,\n",
              " 'last': 238,\n",
              " 'probably': 239,\n",
              " 'tv': 240,\n",
              " 'performance': 241,\n",
              " 'kind': 242,\n",
              " 'away': 243,\n",
              " 'yet': 244,\n",
              " 'fun': 245,\n",
              " 'worst': 246,\n",
              " 'sure': 247,\n",
              " 'rather': 248,\n",
              " 'hard': 249,\n",
              " 'girl': 250,\n",
              " 'anyone': 251,\n",
              " 'each': 252,\n",
              " 'played': 253,\n",
              " 'day': 254,\n",
              " 'found': 255,\n",
              " 'looking': 256,\n",
              " 'woman': 257,\n",
              " 'screen': 258,\n",
              " 'although': 259,\n",
              " 'our': 260,\n",
              " 'especially': 261,\n",
              " 'believe': 262,\n",
              " 'having': 263,\n",
              " 'trying': 264,\n",
              " 'course': 265,\n",
              " 'dvd': 266,\n",
              " 'everything': 267,\n",
              " 'set': 268,\n",
              " 'goes': 269,\n",
              " 'comes': 270,\n",
              " 'put': 271,\n",
              " 'ending': 272,\n",
              " 'maybe': 273,\n",
              " 'place': 274,\n",
              " 'book': 275,\n",
              " 'shows': 276,\n",
              " 'three': 277,\n",
              " 'worth': 278,\n",
              " 'different': 279,\n",
              " 'main': 280,\n",
              " 'once': 281,\n",
              " 'sense': 282,\n",
              " 'american': 283,\n",
              " 'reason': 284,\n",
              " 'looks': 285,\n",
              " 'effects': 286,\n",
              " 'watched': 287,\n",
              " 'play': 288,\n",
              " 'true': 289,\n",
              " 'money': 290,\n",
              " 'actor': 291,\n",
              " \"wasn't\": 292,\n",
              " 'job': 293,\n",
              " 'together': 294,\n",
              " 'war': 295,\n",
              " 'someone': 296,\n",
              " 'plays': 297,\n",
              " 'instead': 298,\n",
              " 'high': 299,\n",
              " 'during': 300,\n",
              " 'said': 301,\n",
              " 'year': 302,\n",
              " 'half': 303,\n",
              " 'everyone': 304,\n",
              " 'later': 305,\n",
              " 'takes': 306,\n",
              " '1': 307,\n",
              " 'seem': 308,\n",
              " 'audience': 309,\n",
              " 'special': 310,\n",
              " 'beautiful': 311,\n",
              " 'left': 312,\n",
              " 'himself': 313,\n",
              " 'seeing': 314,\n",
              " 'john': 315,\n",
              " 'night': 316,\n",
              " 'black': 317,\n",
              " 'version': 318,\n",
              " 'shot': 319,\n",
              " 'excellent': 320,\n",
              " 'idea': 321,\n",
              " 'house': 322,\n",
              " 'mind': 323,\n",
              " 'star': 324,\n",
              " 'wife': 325,\n",
              " 'fan': 326,\n",
              " 'death': 327,\n",
              " 'used': 328,\n",
              " 'else': 329,\n",
              " 'simply': 330,\n",
              " 'nice': 331,\n",
              " 'budget': 332,\n",
              " 'poor': 333,\n",
              " 'short': 334,\n",
              " 'completely': 335,\n",
              " 'second': 336,\n",
              " \"you're\": 337,\n",
              " '3': 338,\n",
              " 'read': 339,\n",
              " 'along': 340,\n",
              " 'less': 341,\n",
              " 'top': 342,\n",
              " 'help': 343,\n",
              " 'home': 344,\n",
              " 'men': 345,\n",
              " 'either': 346,\n",
              " 'line': 347,\n",
              " 'boring': 348,\n",
              " 'dead': 349,\n",
              " 'friends': 350,\n",
              " 'kids': 351,\n",
              " 'try': 352,\n",
              " 'production': 353,\n",
              " 'enjoy': 354,\n",
              " 'camera': 355,\n",
              " 'use': 356,\n",
              " 'wrong': 357,\n",
              " 'given': 358,\n",
              " 'low': 359,\n",
              " 'classic': 360,\n",
              " 'father': 361,\n",
              " 'need': 362,\n",
              " 'full': 363,\n",
              " 'stupid': 364,\n",
              " 'until': 365,\n",
              " 'next': 366,\n",
              " 'performances': 367,\n",
              " 'school': 368,\n",
              " 'hollywood': 369,\n",
              " 'rest': 370,\n",
              " 'truly': 371,\n",
              " 'awful': 372,\n",
              " 'video': 373,\n",
              " 'couple': 374,\n",
              " 'start': 375,\n",
              " 'sex': 376,\n",
              " 'recommend': 377,\n",
              " 'women': 378,\n",
              " 'let': 379,\n",
              " 'tell': 380,\n",
              " 'terrible': 381,\n",
              " 'remember': 382,\n",
              " 'mean': 383,\n",
              " 'came': 384,\n",
              " 'understand': 385,\n",
              " 'getting': 386,\n",
              " 'perhaps': 387,\n",
              " 'moments': 388,\n",
              " 'name': 389,\n",
              " 'keep': 390,\n",
              " 'face': 391,\n",
              " 'itself': 392,\n",
              " 'wonderful': 393,\n",
              " 'playing': 394,\n",
              " 'human': 395,\n",
              " 'style': 396,\n",
              " 'small': 397,\n",
              " 'episode': 398,\n",
              " 'perfect': 399,\n",
              " 'others': 400,\n",
              " 'person': 401,\n",
              " 'doing': 402,\n",
              " 'often': 403,\n",
              " 'early': 404,\n",
              " 'stars': 405,\n",
              " 'definitely': 406,\n",
              " 'written': 407,\n",
              " 'head': 408,\n",
              " 'lines': 409,\n",
              " 'dialogue': 410,\n",
              " 'gives': 411,\n",
              " 'piece': 412,\n",
              " \"couldn't\": 413,\n",
              " 'went': 414,\n",
              " 'finally': 415,\n",
              " 'mother': 416,\n",
              " 'case': 417,\n",
              " 'title': 418,\n",
              " 'absolutely': 419,\n",
              " 'boy': 420,\n",
              " 'live': 421,\n",
              " 'yes': 422,\n",
              " 'laugh': 423,\n",
              " 'certainly': 424,\n",
              " 'liked': 425,\n",
              " 'become': 426,\n",
              " 'worse': 427,\n",
              " 'entertaining': 428,\n",
              " 'oh': 429,\n",
              " 'sort': 430,\n",
              " 'loved': 431,\n",
              " 'lost': 432,\n",
              " 'hope': 433,\n",
              " 'called': 434,\n",
              " 'picture': 435,\n",
              " 'felt': 436,\n",
              " 'overall': 437,\n",
              " 'entire': 438,\n",
              " 'mr': 439,\n",
              " 'several': 440,\n",
              " 'based': 441,\n",
              " 'supposed': 442,\n",
              " 'cinema': 443,\n",
              " 'friend': 444,\n",
              " 'guys': 445,\n",
              " 'sound': 446,\n",
              " '5': 447,\n",
              " 'problem': 448,\n",
              " 'drama': 449,\n",
              " 'against': 450,\n",
              " 'waste': 451,\n",
              " 'white': 452,\n",
              " 'beginning': 453,\n",
              " '4': 454,\n",
              " 'fans': 455,\n",
              " 'totally': 456,\n",
              " 'dark': 457,\n",
              " 'care': 458,\n",
              " 'direction': 459,\n",
              " 'humor': 460,\n",
              " 'wanted': 461,\n",
              " \"she's\": 462,\n",
              " 'seemed': 463,\n",
              " 'game': 464,\n",
              " 'under': 465,\n",
              " 'children': 466,\n",
              " 'despite': 467,\n",
              " 'lives': 468,\n",
              " 'lead': 469,\n",
              " 'guess': 470,\n",
              " 'example': 471,\n",
              " 'already': 472,\n",
              " 'final': 473,\n",
              " 'throughout': 474,\n",
              " \"you'll\": 475,\n",
              " 'turn': 476,\n",
              " 'evil': 477,\n",
              " 'becomes': 478,\n",
              " 'unfortunately': 479,\n",
              " 'able': 480,\n",
              " 'quality': 481,\n",
              " \"i'd\": 482,\n",
              " 'days': 483,\n",
              " 'history': 484,\n",
              " 'fine': 485,\n",
              " 'side': 486,\n",
              " 'wants': 487,\n",
              " 'heart': 488,\n",
              " 'horrible': 489,\n",
              " 'writing': 490,\n",
              " 'amazing': 491,\n",
              " 'b': 492,\n",
              " 'flick': 493,\n",
              " 'killer': 494,\n",
              " 'run': 495,\n",
              " 'son': 496,\n",
              " '\\x96': 497,\n",
              " 'michael': 498,\n",
              " 'works': 499,\n",
              " 'close': 500,\n",
              " \"they're\": 501,\n",
              " 'act': 502,\n",
              " 'art': 503,\n",
              " 'matter': 504,\n",
              " 'kill': 505,\n",
              " 'etc': 506,\n",
              " 'tries': 507,\n",
              " \"won't\": 508,\n",
              " 'past': 509,\n",
              " 'town': 510,\n",
              " 'turns': 511,\n",
              " 'enjoyed': 512,\n",
              " 'brilliant': 513,\n",
              " 'gave': 514,\n",
              " 'behind': 515,\n",
              " 'parts': 516,\n",
              " 'stuff': 517,\n",
              " 'genre': 518,\n",
              " 'eyes': 519,\n",
              " 'car': 520,\n",
              " 'favorite': 521,\n",
              " 'directed': 522,\n",
              " 'late': 523,\n",
              " 'hand': 524,\n",
              " 'expect': 525,\n",
              " 'soon': 526,\n",
              " 'hour': 527,\n",
              " 'obviously': 528,\n",
              " 'themselves': 529,\n",
              " 'sometimes': 530,\n",
              " 'killed': 531,\n",
              " 'actress': 532,\n",
              " 'thinking': 533,\n",
              " 'child': 534,\n",
              " 'girls': 535,\n",
              " 'viewer': 536,\n",
              " 'starts': 537,\n",
              " 'city': 538,\n",
              " 'myself': 539,\n",
              " 'decent': 540,\n",
              " 'highly': 541,\n",
              " 'stop': 542,\n",
              " 'type': 543,\n",
              " 'self': 544,\n",
              " 'god': 545,\n",
              " 'says': 546,\n",
              " 'group': 547,\n",
              " 'anyway': 548,\n",
              " 'voice': 549,\n",
              " 'took': 550,\n",
              " 'known': 551,\n",
              " 'blood': 552,\n",
              " 'kid': 553,\n",
              " 'heard': 554,\n",
              " 'happens': 555,\n",
              " 'except': 556,\n",
              " 'fight': 557,\n",
              " 'feeling': 558,\n",
              " 'experience': 559,\n",
              " 'coming': 560,\n",
              " 'slow': 561,\n",
              " 'daughter': 562,\n",
              " 'writer': 563,\n",
              " 'stories': 564,\n",
              " 'moment': 565,\n",
              " 'leave': 566,\n",
              " 'told': 567,\n",
              " 'extremely': 568,\n",
              " 'score': 569,\n",
              " 'violence': 570,\n",
              " 'involved': 571,\n",
              " 'police': 572,\n",
              " 'strong': 573,\n",
              " 'chance': 574,\n",
              " 'lack': 575,\n",
              " 'cannot': 576,\n",
              " 'hit': 577,\n",
              " 'roles': 578,\n",
              " 'hilarious': 579,\n",
              " 's': 580,\n",
              " 'happen': 581,\n",
              " 'wonder': 582,\n",
              " 'particularly': 583,\n",
              " 'ok': 584,\n",
              " 'including': 585,\n",
              " 'living': 586,\n",
              " 'save': 587,\n",
              " 'looked': 588,\n",
              " \"wouldn't\": 589,\n",
              " 'crap': 590,\n",
              " 'simple': 591,\n",
              " 'please': 592,\n",
              " 'murder': 593,\n",
              " 'cool': 594,\n",
              " 'obvious': 595,\n",
              " 'happened': 596,\n",
              " 'complete': 597,\n",
              " 'cut': 598,\n",
              " 'serious': 599,\n",
              " 'age': 600,\n",
              " 'gore': 601,\n",
              " 'attempt': 602,\n",
              " 'hell': 603,\n",
              " 'ago': 604,\n",
              " 'song': 605,\n",
              " 'shown': 606,\n",
              " 'taken': 607,\n",
              " 'english': 608,\n",
              " 'james': 609,\n",
              " 'robert': 610,\n",
              " 'david': 611,\n",
              " 'seriously': 612,\n",
              " 'released': 613,\n",
              " 'reality': 614,\n",
              " 'opening': 615,\n",
              " 'jokes': 616,\n",
              " 'interest': 617,\n",
              " 'across': 618,\n",
              " 'none': 619,\n",
              " 'hero': 620,\n",
              " 'exactly': 621,\n",
              " 'possible': 622,\n",
              " 'today': 623,\n",
              " 'alone': 624,\n",
              " 'sad': 625,\n",
              " 'brother': 626,\n",
              " 'number': 627,\n",
              " 'career': 628,\n",
              " 'saying': 629,\n",
              " \"film's\": 630,\n",
              " 'usually': 631,\n",
              " 'hours': 632,\n",
              " 'cinematography': 633,\n",
              " 'talent': 634,\n",
              " 'view': 635,\n",
              " 'annoying': 636,\n",
              " 'running': 637,\n",
              " 'yourself': 638,\n",
              " 'relationship': 639,\n",
              " 'documentary': 640,\n",
              " 'wish': 641,\n",
              " 'order': 642,\n",
              " 'huge': 643,\n",
              " 'whose': 644,\n",
              " 'shots': 645,\n",
              " 'ridiculous': 646,\n",
              " 'taking': 647,\n",
              " 'important': 648,\n",
              " 'light': 649,\n",
              " 'body': 650,\n",
              " 'middle': 651,\n",
              " 'level': 652,\n",
              " 'ends': 653,\n",
              " 'female': 654,\n",
              " 'call': 655,\n",
              " 'started': 656,\n",
              " \"i'll\": 657,\n",
              " 'husband': 658,\n",
              " 'four': 659,\n",
              " 'power': 660,\n",
              " 'word': 661,\n",
              " 'turned': 662,\n",
              " 'major': 663,\n",
              " 'opinion': 664,\n",
              " 'change': 665,\n",
              " 'mostly': 666,\n",
              " 'usual': 667,\n",
              " 'silly': 668,\n",
              " 'scary': 669,\n",
              " 'rating': 670,\n",
              " 'beyond': 671,\n",
              " 'somewhat': 672,\n",
              " 'ones': 673,\n",
              " 'happy': 674,\n",
              " 'words': 675,\n",
              " 'room': 676,\n",
              " 'knows': 677,\n",
              " 'knew': 678,\n",
              " 'country': 679,\n",
              " 'disappointed': 680,\n",
              " 'talking': 681,\n",
              " 'novel': 682,\n",
              " 'apparently': 683,\n",
              " 'non': 684,\n",
              " 'strange': 685,\n",
              " 'upon': 686,\n",
              " 'attention': 687,\n",
              " 'basically': 688,\n",
              " 'finds': 689,\n",
              " 'single': 690,\n",
              " 'cheap': 691,\n",
              " 'modern': 692,\n",
              " 'due': 693,\n",
              " 'jack': 694,\n",
              " 'musical': 695,\n",
              " 'television': 696,\n",
              " 'problems': 697,\n",
              " 'miss': 698,\n",
              " 'episodes': 699,\n",
              " 'clearly': 700,\n",
              " 'local': 701,\n",
              " '7': 702,\n",
              " 'british': 703,\n",
              " 'thriller': 704,\n",
              " 'talk': 705,\n",
              " 'events': 706,\n",
              " 'five': 707,\n",
              " 'sequence': 708,\n",
              " \"aren't\": 709,\n",
              " 'class': 710,\n",
              " 'french': 711,\n",
              " 'moving': 712,\n",
              " 'ten': 713,\n",
              " 'fast': 714,\n",
              " 'earth': 715,\n",
              " 'review': 716,\n",
              " 'tells': 717,\n",
              " 'predictable': 718,\n",
              " 'songs': 719,\n",
              " 'team': 720,\n",
              " 'comic': 721,\n",
              " 'straight': 722,\n",
              " 'whether': 723,\n",
              " '8': 724,\n",
              " 'die': 725,\n",
              " 'add': 726,\n",
              " 'dialog': 727,\n",
              " 'entertainment': 728,\n",
              " 'above': 729,\n",
              " 'sets': 730,\n",
              " 'future': 731,\n",
              " 'enjoyable': 732,\n",
              " 'appears': 733,\n",
              " 'near': 734,\n",
              " 'space': 735,\n",
              " 'easily': 736,\n",
              " 'hate': 737,\n",
              " 'soundtrack': 738,\n",
              " 'bring': 739,\n",
              " 'giving': 740,\n",
              " 'lots': 741,\n",
              " 'romantic': 742,\n",
              " 'similar': 743,\n",
              " 'george': 744,\n",
              " 'supporting': 745,\n",
              " 'release': 746,\n",
              " 'mention': 747,\n",
              " 'within': 748,\n",
              " 'filmed': 749,\n",
              " 'message': 750,\n",
              " 'sequel': 751,\n",
              " 'clear': 752,\n",
              " 'falls': 753,\n",
              " 'needs': 754,\n",
              " \"haven't\": 755,\n",
              " 'dull': 756,\n",
              " 'suspense': 757,\n",
              " 'eye': 758,\n",
              " 'bunch': 759,\n",
              " 'surprised': 760,\n",
              " 'showing': 761,\n",
              " 'sorry': 762,\n",
              " 'tried': 763,\n",
              " 'certain': 764,\n",
              " 'working': 765,\n",
              " 'easy': 766,\n",
              " 'ways': 767,\n",
              " 'theme': 768,\n",
              " 'theater': 769,\n",
              " 'among': 770,\n",
              " 'named': 771,\n",
              " \"what's\": 772,\n",
              " 'storyline': 773,\n",
              " 'monster': 774,\n",
              " 'king': 775,\n",
              " 'stay': 776,\n",
              " 'effort': 777,\n",
              " 'minute': 778,\n",
              " 'fall': 779,\n",
              " 'stand': 780,\n",
              " 'gone': 781,\n",
              " 'rock': 782,\n",
              " 'using': 783,\n",
              " '9': 784,\n",
              " 'feature': 785,\n",
              " 'comments': 786,\n",
              " 'buy': 787,\n",
              " \"'\": 788,\n",
              " 't': 789,\n",
              " 'typical': 790,\n",
              " 'sister': 791,\n",
              " 'editing': 792,\n",
              " 'tale': 793,\n",
              " 'avoid': 794,\n",
              " 'deal': 795,\n",
              " 'dr': 796,\n",
              " 'mystery': 797,\n",
              " 'doubt': 798,\n",
              " 'fantastic': 799,\n",
              " 'kept': 800,\n",
              " 'nearly': 801,\n",
              " 'feels': 802,\n",
              " 'okay': 803,\n",
              " 'subject': 804,\n",
              " 'viewing': 805,\n",
              " 'elements': 806,\n",
              " 'oscar': 807,\n",
              " 'check': 808,\n",
              " 'points': 809,\n",
              " 'realistic': 810,\n",
              " 'greatest': 811,\n",
              " 'means': 812,\n",
              " 'herself': 813,\n",
              " 'parents': 814,\n",
              " 'famous': 815,\n",
              " 'imagine': 816,\n",
              " 'rent': 817,\n",
              " 'viewers': 818,\n",
              " 'crime': 819,\n",
              " 'richard': 820,\n",
              " 'form': 821,\n",
              " 'peter': 822,\n",
              " 'actual': 823,\n",
              " 'lady': 824,\n",
              " 'general': 825,\n",
              " 'dog': 826,\n",
              " 'follow': 827,\n",
              " 'believable': 828,\n",
              " 'period': 829,\n",
              " 'red': 830,\n",
              " 'brought': 831,\n",
              " 'move': 832,\n",
              " 'material': 833,\n",
              " 'forget': 834,\n",
              " 'somehow': 835,\n",
              " 'begins': 836,\n",
              " 're': 837,\n",
              " 'reviews': 838,\n",
              " 'animation': 839,\n",
              " 'paul': 840,\n",
              " \"you've\": 841,\n",
              " 'leads': 842,\n",
              " 'weak': 843,\n",
              " 'figure': 844,\n",
              " 'surprise': 845,\n",
              " 'sit': 846,\n",
              " 'hear': 847,\n",
              " 'average': 848,\n",
              " 'open': 849,\n",
              " 'sequences': 850,\n",
              " 'atmosphere': 851,\n",
              " 'killing': 852,\n",
              " 'eventually': 853,\n",
              " 'tom': 854,\n",
              " 'learn': 855,\n",
              " 'premise': 856,\n",
              " 'wait': 857,\n",
              " '20': 858,\n",
              " 'sci': 859,\n",
              " 'deep': 860,\n",
              " 'fi': 861,\n",
              " 'expected': 862,\n",
              " 'whatever': 863,\n",
              " 'indeed': 864,\n",
              " 'lame': 865,\n",
              " 'particular': 866,\n",
              " 'poorly': 867,\n",
              " 'note': 868,\n",
              " 'dance': 869,\n",
              " 'imdb': 870,\n",
              " 'shame': 871,\n",
              " 'situation': 872,\n",
              " 'third': 873,\n",
              " 'box': 874,\n",
              " 'york': 875,\n",
              " 'truth': 876,\n",
              " 'decided': 877,\n",
              " 'free': 878,\n",
              " 'hot': 879,\n",
              " \"who's\": 880,\n",
              " 'difficult': 881,\n",
              " 'season': 882,\n",
              " 'needed': 883,\n",
              " 'acted': 884,\n",
              " 'leaves': 885,\n",
              " 'unless': 886,\n",
              " 'emotional': 887,\n",
              " 'possibly': 888,\n",
              " 'romance': 889,\n",
              " 'sexual': 890,\n",
              " 'gay': 891,\n",
              " 'boys': 892,\n",
              " 'footage': 893,\n",
              " 'write': 894,\n",
              " 'western': 895,\n",
              " 'credits': 896,\n",
              " 'forced': 897,\n",
              " 'memorable': 898,\n",
              " 'reading': 899,\n",
              " 'became': 900,\n",
              " 'doctor': 901,\n",
              " 'otherwise': 902,\n",
              " 'air': 903,\n",
              " 'begin': 904,\n",
              " 'de': 905,\n",
              " 'crew': 906,\n",
              " 'question': 907,\n",
              " 'society': 908,\n",
              " 'meet': 909,\n",
              " 'male': 910,\n",
              " 'meets': 911,\n",
              " \"let's\": 912,\n",
              " 'plus': 913,\n",
              " 'cheesy': 914,\n",
              " 'hands': 915,\n",
              " 'superb': 916,\n",
              " 'screenplay': 917,\n",
              " 'interested': 918,\n",
              " 'beauty': 919,\n",
              " 'street': 920,\n",
              " 'features': 921,\n",
              " 'whom': 922,\n",
              " 'perfectly': 923,\n",
              " 'masterpiece': 924,\n",
              " 'laughs': 925,\n",
              " 'stage': 926,\n",
              " 'nature': 927,\n",
              " 'effect': 928,\n",
              " 'comment': 929,\n",
              " 'forward': 930,\n",
              " 'nor': 931,\n",
              " 'badly': 932,\n",
              " 'previous': 933,\n",
              " 'e': 934,\n",
              " 'sounds': 935,\n",
              " 'japanese': 936,\n",
              " 'weird': 937,\n",
              " 'island': 938,\n",
              " 'inside': 939,\n",
              " 'personal': 940,\n",
              " 'quickly': 941,\n",
              " 'total': 942,\n",
              " 'keeps': 943,\n",
              " 'towards': 944,\n",
              " 'america': 945,\n",
              " 'result': 946,\n",
              " 'crazy': 947,\n",
              " 'battle': 948,\n",
              " 'worked': 949,\n",
              " 'setting': 950,\n",
              " 'incredibly': 951,\n",
              " 'background': 952,\n",
              " 'earlier': 953,\n",
              " 'mess': 954,\n",
              " 'cop': 955,\n",
              " 'writers': 956,\n",
              " 'fire': 957,\n",
              " 'copy': 958,\n",
              " 'realize': 959,\n",
              " 'unique': 960,\n",
              " 'dumb': 961,\n",
              " 'powerful': 962,\n",
              " 'lee': 963,\n",
              " 'mark': 964,\n",
              " 'business': 965,\n",
              " 'rate': 966,\n",
              " 'older': 967,\n",
              " 'dramatic': 968,\n",
              " 'pay': 969,\n",
              " 'following': 970,\n",
              " 'directors': 971,\n",
              " 'girlfriend': 972,\n",
              " 'joke': 973,\n",
              " 'plenty': 974,\n",
              " 'directing': 975,\n",
              " 'various': 976,\n",
              " 'creepy': 977,\n",
              " 'baby': 978,\n",
              " 'appear': 979,\n",
              " 'development': 980,\n",
              " 'brings': 981,\n",
              " 'front': 982,\n",
              " 'dream': 983,\n",
              " 'ask': 984,\n",
              " 'water': 985,\n",
              " 'rich': 986,\n",
              " 'admit': 987,\n",
              " 'bill': 988,\n",
              " 'apart': 989,\n",
              " 'joe': 990,\n",
              " 'fairly': 991,\n",
              " 'political': 992,\n",
              " 'leading': 993,\n",
              " 'reasons': 994,\n",
              " 'portrayed': 995,\n",
              " 'spent': 996,\n",
              " 'telling': 997,\n",
              " 'cover': 998,\n",
              " 'outside': 999,\n",
              " 'present': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bMyGFpVTcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHFAjQLCVs6a",
        "colab_type": "code",
        "outputId": "62e380fe-fac3-4721-835b-783b38d462e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "x_train_text[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"If you cannot enjoy a chick flick, stop right now. If, however, you enjoy films that illustrate complex characters and provide extraordinary acting, read on.<br /><br />Ann Grant Lord is dying. Her two daughters arrive to be at her bedside. Ann begins talking about people from her past of whom the daughters are unaware, and they question as to whether these lost acquaintances are real or imagined. They come to realize that these people from their mother's past are, indeed, real.<br /><br />The story shifts, basically, between 1953 and circa 2000 with a few glimpses at Ann's life between those years. It was in 1953 that Ann met the love of her life and experienced her life's greatest tragedy.<br /><br />One of Ann's two best friends from college, Lila, is being married. Ann's other best friend is Lila's brother, Buddy. Lila and Buddy are the children of a rich Newport family, whereas Ann is a cabaret singer living in Greenwich Village who wants to be a free spirit but is still bound by many of those 1950's conventions.<br /><br />Soon after Ann arrives to be maid of honor at Lila's wedding, she meets the person who will become the pivotal character in the lives of the three - Harris. He is the adult son of a former servant of the family who grew up with Lila and Buddy and has gone on to become a physician in a small New England town. Ann immediately becomes enamored of Harris which adds a complication to the fact that Lila has always been in love with Harris and continues to be. Buddy, also, is in love with Harris, but being 1953, he has redirected that homosexual desire for Harris to his good friend, Ann for he cannot admit to himself that he has a sexual craving for another man. Buddy exhibits his inner frustration outwardly by being the alcoholic, wise-cracking bad boy of the family - much to the chagrin of his very proper and uptight parents.<br /><br />Needless to say, all of these expressed and repressed emotions lead to tragedy - after all this is a chick flick.<br /><br />In the present time, Ann's daughters have become distant from their mother and are suffering their own life realizations and doubts. Constance is working to emotional exhaustion trying to keep up her roll as perfect mother and wife. Nina, having always felt inferior, cannot maintain a relationship.<br /><br />Stir all of these relationships into a span of fifty years, and you get an intriguing look at society, its values, and its effects upon the personalities and actions of the complex people involved.<br /><br />All of the acting in Evening is excellent, but there are some extraordinary performances and scenes - along with two unique family relationships - that make this film so very, very special.<br /><br />Claire Danes plays the 1950's Ann, and she does it in a style that clearly shows an intelligent woman of those times who is conflicted by what she is supposed to do as opposed to what she wants to do. Her performance is not easily forgettable.<br /><br />Vanessa Redgrave plays the dying Ann whose mind shifts from the present, to the past, to flights of fantasy, and of course, Redgrave pulls it all off with sterling style.<br /><br />Natasha Richardson - Redgrave's real daughter - plays Ann's daughter, Constance, in the film. The scenes between this real life mother and daughter playing fictional mother and daughter are an insightful treat to watch.<br /><br />Toni Collette plays Ann's other daughter, Nina. Nina spends a good deal of her time being depressed and feeling sorry for herself while shutting out a good man who loves her as well as her mother and sister. Collette is perfect for a part such as this, but I have never seen her give a bad or unbelievable performance no matter what part she plays.<br /><br />Mamie Gummer plays 1950's Lila and shows us a woman even more conflicted of her expected role in life than her good friend, Ann. She is very good.<br /><br />Meryl Streep - Gummer's mother - plays present day Lila. What is there to say about Meryl Streep other than she always gives an insightful and rewarding performance.<br /><br />Director Lajos Koltai states in the DVD extras that he sought out Glenn Close to play the relatively small part of Lila's mother because he felt she was the only actress he could think of to play one scene in the film. He certainly was right, and Close's performance in that one scene etches it in your mind. All the other scenes in which Close is Lila's very proper mother, and you get another performance to treasure.<br /><br />There are three other scenes in the film, combined with the one featuring Close described above, that make the whole movie worth watching. On Lila's wedding day, Ann comes into her room and crawls into to bed with her friend to discuss Lila's misforgivings about her upcoming wedding to a man she clearly does not love. This scene is repeated fifty years later when Lila comes and crawls into bed with her dying friend Ann to talk about the lives they have lived. In this latter scene, Streep and Redgrave are enthralling.<br /><br />The other memorable scene - at least to me - is when Buddy declares his love for Ann. Hugh Dancy as Buddy gives us a heartbreaking performance of a young man torn apart by his conflicting sexual feelings. His performance is superior.<br /><br />Chick flick? Yes. A very special film with unbelievable acting, directing, and scenery? Definitely. I cannot recommend Evening too much.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XcaGQCvVxyH",
        "colab_type": "code",
        "outputId": "ef87676a-4ed6-4243-ec0d-16ad190dcdfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "np.array(x_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  43,   22,  576,  354,    3, 2164,  493,  542,  203,  146,   43,\n",
              "        188,   22,  354,  104,   12, 9015, 1300,  102,    2, 1688, 2499,\n",
              "        113,  339,   20,    7,    7, 2137, 2567, 1779,    6, 1685,   40,\n",
              "        105, 3082, 3677,    5,   26,   30,   40, 2137,  836,  681,   42,\n",
              "         83,   36,   40,  509,    4,  922,    1, 3082,   23, 5147,    2,\n",
              "         33,  907,   14,    5,  723,  132,  432,   23,  144,   38, 4033,\n",
              "         33,  215,    5,  959,   12,  132,   83,   36,   65, 4233,  509,\n",
              "         23,  864,  144,    7,    7,    1,   64, 6594,  688,  201, 7364,\n",
              "          2, 8089, 3359,   16,    3,  171, 6953,   30,  114,  201,  143,\n",
              "        153,    9,   13,    8, 7364,   12, 2137, 1819,    1,  112,    4,\n",
              "         40,  114,    2, 2339,   40, 6514,  811, 1637,    7,    7,   27,\n",
              "          4,  105,  116,  350,   36, 1121,    6,  109, 1062,   79,  116,\n",
              "        444,    6,  626, 1867,    2, 1867,   23,    1,  466,    4,    3,\n",
              "        986,  236, 2962, 2137,    6,    3, 1843,  586,    8, 1994,   35,\n",
              "        487,    5,   26,    3,  878, 1174,   18,    6,  130, 2761,   31,\n",
              "        106,    4,  143, 3922, 5877,    7,    7,  526,  100, 2137, 2672,\n",
              "          5,   26, 5238,    4, 3065,   30, 2095,   59,  911,    1,  401,\n",
              "         35,   80,  426,    1, 7599,  108,    8,    1,  468,    4,    1,\n",
              "        277, 2446,   28,    6,    1, 1241,  496,    4,    3, 1112, 5479,\n",
              "          4,    1,  236,   35, 2160,   53,   16,    2, 1867,    2,   45,\n",
              "        781,   20,    5,  426,    3,    8,    3,  397,  168, 1966,  510,\n",
              "       2137, 1220,  478,    4, 2446,   60, 1530,    3,    5,    1,  192,\n",
              "         12,   45,  211,   75,    8,  112,   16, 2446,    2, 2079,    5,\n",
              "         26, 1867,   81,    6,    8,  112,   16, 2446,   18,  109, 7364,\n",
              "         28,   45,   12, 4086, 1955,   15, 2446,    5,   24,   49,  444,\n",
              "       2137,   15,   28,  576,  987,    5,  313,   12,   28,   45,    3,\n",
              "        890,   15,  156,  128, 1867,   24, 2518, 4592,   31,  109,    1,\n",
              "       4881, 1626, 5422,   74,  420,    4,    1,  236,   72,    5,    1,\n",
              "          4,   24,   52, 2289,    2, 8306,  814,    7,    7, 3127,    5,\n",
              "        131,   29,    4,  132, 4882,    2, 6731, 1334,  469,    5, 1637,\n",
              "        100,   29,   11,    6,    3, 2164,  493,    7,    7,    8,    1,\n",
              "       1000,   55, 3082,   25,  426, 3530,   36,   65,  416,    2,   23,\n",
              "       2150,   65,  199,  114,    2, 5251,    6,  765,    5,  887,  264,\n",
              "          5,  390,   53,   40, 1833,   14,  399,  416,    2,  325, 7365,\n",
              "        263,  211,  436, 4848,  576, 4234,    3,  639,    7,    7, 9207,\n",
              "         29,    4,  132, 1497,   82,    3, 6418,    4, 5030,  153,    2,\n",
              "         22,   76,   32, 1723,  163,   30,  908,   92, 1196,    2,   92,\n",
              "        286,  686,    1, 3281,    2, 1640,    4,    1, 1300,   83,  571,\n",
              "          7,    7,   29,    4,    1,  113,    8, 2290,    6,  320,   18,\n",
              "         46,   23,   47, 2499,  367,    2,  134,  340,   16,  105,  960,\n",
              "        236, 1497,   12,   94,   11,   19,   34,   52,   52,  310,    7,\n",
              "          7, 3710, 5878,  297,    1, 3922, 2137,    2,   59,  124,    9,\n",
              "          8,    3,  396,   12,  700,  276,   32, 1105,  257,    4,  143,\n",
              "        209,   35,    6, 8230,   31,   48,   59,    6,  442,    5,   77,\n",
              "         14, 3336,    5,   48,   59,  487,    5,   77,   40,  241,    6,\n",
              "         21,  736, 2508,    7,    7, 6732, 8459,  297,    1, 1685, 2137,\n",
              "        644,  323, 6594,   36,    1, 1000,    5,    1,  509,    5,    4,\n",
              "       1029,    2,    4,  265, 8459, 2596,    9,   29,  122,   16, 7241,\n",
              "        396,    7,    7, 9208, 5745,  144,  562,  297,  562,    8,    1,\n",
              "         19,    1,  134,  201,   11,  144,  114,  416,    2,  562,  394,\n",
              "       2963,  416,    2,  562,   23,   32, 5541, 1774,    5,  103,    7,\n",
              "          7, 6515,  297,   79,  562, 7365, 7365, 2396,    3,   49,  795,\n",
              "          4,   40,   55,  109, 4118,    2,  558,  762,   15,  813,  136,\n",
              "         41,    3,   49,  128,   35, 1357,   40,   14,   69,   14,   40,\n",
              "        416,    2,  791,    6,  399,   15,    3,  173,  138,   14,   11,\n",
              "         18,   10,   25,  110,  107,   40,  197,    3,   74,   38, 1360,\n",
              "        241,   54,  504,   48,  173,   59,  297,    7,    7,  297, 3922,\n",
              "          2,  276,  176,    3,  257,   57,   51, 8230,    4,   40,  862,\n",
              "        214,    8,  114,   71,   40,   49,  444, 2137,   59,    6,   52,\n",
              "         49,    7,    7, 4806, 4161,  416,  297, 1000,  254,   48,    6,\n",
              "         46,    5,  131,   42, 4806, 4161,   79,   71,   59,  211,  411,\n",
              "         32, 5541,    2, 6340,  241,    7,    7,  164, 1653,    8,    1,\n",
              "        266, 2305,   12,   28, 6686,   41, 3639,  500,    5,  288,    1,\n",
              "       2406,  397,  173,    4,  416,   84,   28,  436,   59,   13,    1,\n",
              "         61,  532,   28,   98,  101,    4,    5,  288,   27,  129,    8,\n",
              "          1,   19,   28,  424,   13,  203,    2,  241,    8,   12,   27,\n",
              "        129,    9,    8,  125,  323,   29,    1,   79,  134,    8,   60,\n",
              "        500,    6,   52, 2289,  416,    2,   22,   76,  156,  241,    5,\n",
              "       2734,    7,    7,   46,   23,  277,   79,  134,    8,    1,   19,\n",
              "       2681,   16,    1,   27, 1990,  500, 2090,  729,   12,   94,    1,\n",
              "        223,   17,  278,  147,   20, 2095,  254, 2137,  270,   82,   40,\n",
              "        676,    2,   82,    5, 1264,   16,   40,  444,    5, 4299,   42,\n",
              "         40, 7418, 2095,    5,    3,  128,   59,  700,  124,   21,  112,\n",
              "         11,  129,    6, 2628, 5030,  153,  305,   50,  270,    2,   82,\n",
              "       1264,   16,   40, 1685,  444, 2137,    5,  705,   42,    1,  468,\n",
              "         33,   25, 1414,    8,   11, 1598,  129, 4161,    2, 8459,   23,\n",
              "       8927,    7,    7,    1,   79,  898,  129,   30,  224,    5,   68,\n",
              "          6,   50, 1867,   24,  112,   15, 2137, 4737,   14, 1867,  411,\n",
              "        176,    3, 5148,  241,    4,    3,  186,  128, 3077,  989,   31,\n",
              "         24,  890, 1395,   24,  241,    6, 1747,    7,    7, 2164,  493,\n",
              "        422,    3,   52,  310,   19,   16, 1360,  113,  975,    2, 1305,\n",
              "        406,   10,  576,  377, 2290,   96,   72])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7w0AMpHWiPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okzxeaiXWlvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deh-2qpWWspQ",
        "colab_type": "code",
        "outputId": "c04fd445-600b-429f-fe97-c3c6736e55bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(num_tokens)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221.27716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPE2KrLBWylN",
        "colab_type": "code",
        "outputId": "87beb063-db31-4f45-d3eb-ed76179798ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.max(num_tokens)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEJrsZFlW1m0",
        "colab_type": "code",
        "outputId": "ed1029a8-1935-4953-c1c5-ace382a0d676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyUNdYEFW7W4",
        "colab_type": "code",
        "outputId": "a1dd0951-a091-47e0-e0bc-9f69821e9788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.94532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGR98RyrW_sH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad = 'pre'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN5RgZmrXEVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
        "                            padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxnfAP8bXI3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIFojpUAXP6F",
        "colab_type": "code",
        "outputId": "d5b501f4-d71e-499c-a459-37ab6cb35b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3FT6gRHXRIA",
        "colab_type": "code",
        "outputId": "516840e7-cf06-42a0-991c-d49f430dcb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_test_pad.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma2q04KnXUV2",
        "colab_type": "code",
        "outputId": "b16114e7-dcaa-41fc-e639-5d4885daacf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "np.array(x_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  43,   22,  576,  354,    3, 2164,  493,  542,  203,  146,   43,\n",
              "        188,   22,  354,  104,   12, 9015, 1300,  102,    2, 1688, 2499,\n",
              "        113,  339,   20,    7,    7, 2137, 2567, 1779,    6, 1685,   40,\n",
              "        105, 3082, 3677,    5,   26,   30,   40, 2137,  836,  681,   42,\n",
              "         83,   36,   40,  509,    4,  922,    1, 3082,   23, 5147,    2,\n",
              "         33,  907,   14,    5,  723,  132,  432,   23,  144,   38, 4033,\n",
              "         33,  215,    5,  959,   12,  132,   83,   36,   65, 4233,  509,\n",
              "         23,  864,  144,    7,    7,    1,   64, 6594,  688,  201, 7364,\n",
              "          2, 8089, 3359,   16,    3,  171, 6953,   30,  114,  201,  143,\n",
              "        153,    9,   13,    8, 7364,   12, 2137, 1819,    1,  112,    4,\n",
              "         40,  114,    2, 2339,   40, 6514,  811, 1637,    7,    7,   27,\n",
              "          4,  105,  116,  350,   36, 1121,    6,  109, 1062,   79,  116,\n",
              "        444,    6,  626, 1867,    2, 1867,   23,    1,  466,    4,    3,\n",
              "        986,  236, 2962, 2137,    6,    3, 1843,  586,    8, 1994,   35,\n",
              "        487,    5,   26,    3,  878, 1174,   18,    6,  130, 2761,   31,\n",
              "        106,    4,  143, 3922, 5877,    7,    7,  526,  100, 2137, 2672,\n",
              "          5,   26, 5238,    4, 3065,   30, 2095,   59,  911,    1,  401,\n",
              "         35,   80,  426,    1, 7599,  108,    8,    1,  468,    4,    1,\n",
              "        277, 2446,   28,    6,    1, 1241,  496,    4,    3, 1112, 5479,\n",
              "          4,    1,  236,   35, 2160,   53,   16,    2, 1867,    2,   45,\n",
              "        781,   20,    5,  426,    3,    8,    3,  397,  168, 1966,  510,\n",
              "       2137, 1220,  478,    4, 2446,   60, 1530,    3,    5,    1,  192,\n",
              "         12,   45,  211,   75,    8,  112,   16, 2446,    2, 2079,    5,\n",
              "         26, 1867,   81,    6,    8,  112,   16, 2446,   18,  109, 7364,\n",
              "         28,   45,   12, 4086, 1955,   15, 2446,    5,   24,   49,  444,\n",
              "       2137,   15,   28,  576,  987,    5,  313,   12,   28,   45,    3,\n",
              "        890,   15,  156,  128, 1867,   24, 2518, 4592,   31,  109,    1,\n",
              "       4881, 1626, 5422,   74,  420,    4,    1,  236,   72,    5,    1,\n",
              "          4,   24,   52, 2289,    2, 8306,  814,    7,    7, 3127,    5,\n",
              "        131,   29,    4,  132, 4882,    2, 6731, 1334,  469,    5, 1637,\n",
              "        100,   29,   11,    6,    3, 2164,  493,    7,    7,    8,    1,\n",
              "       1000,   55, 3082,   25,  426, 3530,   36,   65,  416,    2,   23,\n",
              "       2150,   65,  199,  114,    2, 5251,    6,  765,    5,  887,  264,\n",
              "          5,  390,   53,   40, 1833,   14,  399,  416,    2,  325, 7365,\n",
              "        263,  211,  436, 4848,  576, 4234,    3,  639,    7,    7, 9207,\n",
              "         29,    4,  132, 1497,   82,    3, 6418,    4, 5030,  153,    2,\n",
              "         22,   76,   32, 1723,  163,   30,  908,   92, 1196,    2,   92,\n",
              "        286,  686,    1, 3281,    2, 1640,    4,    1, 1300,   83,  571,\n",
              "          7,    7,   29,    4,    1,  113,    8, 2290,    6,  320,   18,\n",
              "         46,   23,   47, 2499,  367,    2,  134,  340,   16,  105,  960,\n",
              "        236, 1497,   12,   94,   11,   19,   34,   52,   52,  310,    7,\n",
              "          7, 3710, 5878,  297,    1, 3922, 2137,    2,   59,  124,    9,\n",
              "          8,    3,  396,   12,  700,  276,   32, 1105,  257,    4,  143,\n",
              "        209,   35,    6, 8230,   31,   48,   59,    6,  442,    5,   77,\n",
              "         14, 3336,    5,   48,   59,  487,    5,   77,   40,  241,    6,\n",
              "         21,  736, 2508,    7,    7, 6732, 8459,  297,    1, 1685, 2137,\n",
              "        644,  323, 6594,   36,    1, 1000,    5,    1,  509,    5,    4,\n",
              "       1029,    2,    4,  265, 8459, 2596,    9,   29,  122,   16, 7241,\n",
              "        396,    7,    7, 9208, 5745,  144,  562,  297,  562,    8,    1,\n",
              "         19,    1,  134,  201,   11,  144,  114,  416,    2,  562,  394,\n",
              "       2963,  416,    2,  562,   23,   32, 5541, 1774,    5,  103,    7,\n",
              "          7, 6515,  297,   79,  562, 7365, 7365, 2396,    3,   49,  795,\n",
              "          4,   40,   55,  109, 4118,    2,  558,  762,   15,  813,  136,\n",
              "         41,    3,   49,  128,   35, 1357,   40,   14,   69,   14,   40,\n",
              "        416,    2,  791,    6,  399,   15,    3,  173,  138,   14,   11,\n",
              "         18,   10,   25,  110,  107,   40,  197,    3,   74,   38, 1360,\n",
              "        241,   54,  504,   48,  173,   59,  297,    7,    7,  297, 3922,\n",
              "          2,  276,  176,    3,  257,   57,   51, 8230,    4,   40,  862,\n",
              "        214,    8,  114,   71,   40,   49,  444, 2137,   59,    6,   52,\n",
              "         49,    7,    7, 4806, 4161,  416,  297, 1000,  254,   48,    6,\n",
              "         46,    5,  131,   42, 4806, 4161,   79,   71,   59,  211,  411,\n",
              "         32, 5541,    2, 6340,  241,    7,    7,  164, 1653,    8,    1,\n",
              "        266, 2305,   12,   28, 6686,   41, 3639,  500,    5,  288,    1,\n",
              "       2406,  397,  173,    4,  416,   84,   28,  436,   59,   13,    1,\n",
              "         61,  532,   28,   98,  101,    4,    5,  288,   27,  129,    8,\n",
              "          1,   19,   28,  424,   13,  203,    2,  241,    8,   12,   27,\n",
              "        129,    9,    8,  125,  323,   29,    1,   79,  134,    8,   60,\n",
              "        500,    6,   52, 2289,  416,    2,   22,   76,  156,  241,    5,\n",
              "       2734,    7,    7,   46,   23,  277,   79,  134,    8,    1,   19,\n",
              "       2681,   16,    1,   27, 1990,  500, 2090,  729,   12,   94,    1,\n",
              "        223,   17,  278,  147,   20, 2095,  254, 2137,  270,   82,   40,\n",
              "        676,    2,   82,    5, 1264,   16,   40,  444,    5, 4299,   42,\n",
              "         40, 7418, 2095,    5,    3,  128,   59,  700,  124,   21,  112,\n",
              "         11,  129,    6, 2628, 5030,  153,  305,   50,  270,    2,   82,\n",
              "       1264,   16,   40, 1685,  444, 2137,    5,  705,   42,    1,  468,\n",
              "         33,   25, 1414,    8,   11, 1598,  129, 4161,    2, 8459,   23,\n",
              "       8927,    7,    7,    1,   79,  898,  129,   30,  224,    5,   68,\n",
              "          6,   50, 1867,   24,  112,   15, 2137, 4737,   14, 1867,  411,\n",
              "        176,    3, 5148,  241,    4,    3,  186,  128, 3077,  989,   31,\n",
              "         24,  890, 1395,   24,  241,    6, 1747,    7,    7, 2164,  493,\n",
              "        422,    3,   52,  310,   19,   16, 1360,  113,  975,    2, 1305,\n",
              "        406,   10,  576,  377, 2290,   96,   72])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wRrZXpwXcKT",
        "colab_type": "code",
        "outputId": "eb032ee6-dffd-4de0-b665-1e9f240a82a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "x_train_pad[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 199,  114,    2, 5251,    6,  765,    5,  887,  264,    5,  390,\n",
              "         53,   40, 1833,   14,  399,  416,    2,  325, 7365,  263,  211,\n",
              "        436, 4848,  576, 4234,    3,  639,    7,    7, 9207,   29,    4,\n",
              "        132, 1497,   82,    3, 6418,    4, 5030,  153,    2,   22,   76,\n",
              "         32, 1723,  163,   30,  908,   92, 1196,    2,   92,  286,  686,\n",
              "          1, 3281,    2, 1640,    4,    1, 1300,   83,  571,    7,    7,\n",
              "         29,    4,    1,  113,    8, 2290,    6,  320,   18,   46,   23,\n",
              "         47, 2499,  367,    2,  134,  340,   16,  105,  960,  236, 1497,\n",
              "         12,   94,   11,   19,   34,   52,   52,  310,    7,    7, 3710,\n",
              "       5878,  297,    1, 3922, 2137,    2,   59,  124,    9,    8,    3,\n",
              "        396,   12,  700,  276,   32, 1105,  257,    4,  143,  209,   35,\n",
              "          6, 8230,   31,   48,   59,    6,  442,    5,   77,   14, 3336,\n",
              "          5,   48,   59,  487,    5,   77,   40,  241,    6,   21,  736,\n",
              "       2508,    7,    7, 6732, 8459,  297,    1, 1685, 2137,  644,  323,\n",
              "       6594,   36,    1, 1000,    5,    1,  509,    5,    4, 1029,    2,\n",
              "          4,  265, 8459, 2596,    9,   29,  122,   16, 7241,  396,    7,\n",
              "          7, 9208, 5745,  144,  562,  297,  562,    8,    1,   19,    1,\n",
              "        134,  201,   11,  144,  114,  416,    2,  562,  394, 2963,  416,\n",
              "          2,  562,   23,   32, 5541, 1774,    5,  103,    7,    7, 6515,\n",
              "        297,   79,  562, 7365, 7365, 2396,    3,   49,  795,    4,   40,\n",
              "         55,  109, 4118,    2,  558,  762,   15,  813,  136,   41,    3,\n",
              "         49,  128,   35, 1357,   40,   14,   69,   14,   40,  416,    2,\n",
              "        791,    6,  399,   15,    3,  173,  138,   14,   11,   18,   10,\n",
              "         25,  110,  107,   40,  197,    3,   74,   38, 1360,  241,   54,\n",
              "        504,   48,  173,   59,  297,    7,    7,  297, 3922,    2,  276,\n",
              "        176,    3,  257,   57,   51, 8230,    4,   40,  862,  214,    8,\n",
              "        114,   71,   40,   49,  444, 2137,   59,    6,   52,   49,    7,\n",
              "          7, 4806, 4161,  416,  297, 1000,  254,   48,    6,   46,    5,\n",
              "        131,   42, 4806, 4161,   79,   71,   59,  211,  411,   32, 5541,\n",
              "          2, 6340,  241,    7,    7,  164, 1653,    8,    1,  266, 2305,\n",
              "         12,   28, 6686,   41, 3639,  500,    5,  288,    1, 2406,  397,\n",
              "        173,    4,  416,   84,   28,  436,   59,   13,    1,   61,  532,\n",
              "         28,   98,  101,    4,    5,  288,   27,  129,    8,    1,   19,\n",
              "         28,  424,   13,  203,    2,  241,    8,   12,   27,  129,    9,\n",
              "          8,  125,  323,   29,    1,   79,  134,    8,   60,  500,    6,\n",
              "         52, 2289,  416,    2,   22,   76,  156,  241,    5, 2734,    7,\n",
              "          7,   46,   23,  277,   79,  134,    8,    1,   19, 2681,   16,\n",
              "          1,   27, 1990,  500, 2090,  729,   12,   94,    1,  223,   17,\n",
              "        278,  147,   20, 2095,  254, 2137,  270,   82,   40,  676,    2,\n",
              "         82,    5, 1264,   16,   40,  444,    5, 4299,   42,   40, 7418,\n",
              "       2095,    5,    3,  128,   59,  700,  124,   21,  112,   11,  129,\n",
              "          6, 2628, 5030,  153,  305,   50,  270,    2,   82, 1264,   16,\n",
              "         40, 1685,  444, 2137,    5,  705,   42,    1,  468,   33,   25,\n",
              "       1414,    8,   11, 1598,  129, 4161,    2, 8459,   23, 8927,    7,\n",
              "          7,    1,   79,  898,  129,   30,  224,    5,   68,    6,   50,\n",
              "       1867,   24,  112,   15, 2137, 4737,   14, 1867,  411,  176,    3,\n",
              "       5148,  241,    4,    3,  186,  128, 3077,  989,   31,   24,  890,\n",
              "       1395,   24,  241,    6, 1747,    7,    7, 2164,  493,  422,    3,\n",
              "         52,  310,   19,   16, 1360,  113,  975,    2, 1305,  406,   10,\n",
              "        576,  377, 2290,   96,   72], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24e4gLnFXghS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bquK6zXcXvdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_string(tokens):\n",
        "    # Map from tokens back to words.\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7th5snR4Xzzx",
        "colab_type": "code",
        "outputId": "fede5805-9619-4b89-d07d-2b4672315a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "x_train_text[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"If you cannot enjoy a chick flick, stop right now. If, however, you enjoy films that illustrate complex characters and provide extraordinary acting, read on.<br /><br />Ann Grant Lord is dying. Her two daughters arrive to be at her bedside. Ann begins talking about people from her past of whom the daughters are unaware, and they question as to whether these lost acquaintances are real or imagined. They come to realize that these people from their mother's past are, indeed, real.<br /><br />The story shifts, basically, between 1953 and circa 2000 with a few glimpses at Ann's life between those years. It was in 1953 that Ann met the love of her life and experienced her life's greatest tragedy.<br /><br />One of Ann's two best friends from college, Lila, is being married. Ann's other best friend is Lila's brother, Buddy. Lila and Buddy are the children of a rich Newport family, whereas Ann is a cabaret singer living in Greenwich Village who wants to be a free spirit but is still bound by many of those 1950's conventions.<br /><br />Soon after Ann arrives to be maid of honor at Lila's wedding, she meets the person who will become the pivotal character in the lives of the three - Harris. He is the adult son of a former servant of the family who grew up with Lila and Buddy and has gone on to become a physician in a small New England town. Ann immediately becomes enamored of Harris which adds a complication to the fact that Lila has always been in love with Harris and continues to be. Buddy, also, is in love with Harris, but being 1953, he has redirected that homosexual desire for Harris to his good friend, Ann for he cannot admit to himself that he has a sexual craving for another man. Buddy exhibits his inner frustration outwardly by being the alcoholic, wise-cracking bad boy of the family - much to the chagrin of his very proper and uptight parents.<br /><br />Needless to say, all of these expressed and repressed emotions lead to tragedy - after all this is a chick flick.<br /><br />In the present time, Ann's daughters have become distant from their mother and are suffering their own life realizations and doubts. Constance is working to emotional exhaustion trying to keep up her roll as perfect mother and wife. Nina, having always felt inferior, cannot maintain a relationship.<br /><br />Stir all of these relationships into a span of fifty years, and you get an intriguing look at society, its values, and its effects upon the personalities and actions of the complex people involved.<br /><br />All of the acting in Evening is excellent, but there are some extraordinary performances and scenes - along with two unique family relationships - that make this film so very, very special.<br /><br />Claire Danes plays the 1950's Ann, and she does it in a style that clearly shows an intelligent woman of those times who is conflicted by what she is supposed to do as opposed to what she wants to do. Her performance is not easily forgettable.<br /><br />Vanessa Redgrave plays the dying Ann whose mind shifts from the present, to the past, to flights of fantasy, and of course, Redgrave pulls it all off with sterling style.<br /><br />Natasha Richardson - Redgrave's real daughter - plays Ann's daughter, Constance, in the film. The scenes between this real life mother and daughter playing fictional mother and daughter are an insightful treat to watch.<br /><br />Toni Collette plays Ann's other daughter, Nina. Nina spends a good deal of her time being depressed and feeling sorry for herself while shutting out a good man who loves her as well as her mother and sister. Collette is perfect for a part such as this, but I have never seen her give a bad or unbelievable performance no matter what part she plays.<br /><br />Mamie Gummer plays 1950's Lila and shows us a woman even more conflicted of her expected role in life than her good friend, Ann. She is very good.<br /><br />Meryl Streep - Gummer's mother - plays present day Lila. What is there to say about Meryl Streep other than she always gives an insightful and rewarding performance.<br /><br />Director Lajos Koltai states in the DVD extras that he sought out Glenn Close to play the relatively small part of Lila's mother because he felt she was the only actress he could think of to play one scene in the film. He certainly was right, and Close's performance in that one scene etches it in your mind. All the other scenes in which Close is Lila's very proper mother, and you get another performance to treasure.<br /><br />There are three other scenes in the film, combined with the one featuring Close described above, that make the whole movie worth watching. On Lila's wedding day, Ann comes into her room and crawls into to bed with her friend to discuss Lila's misforgivings about her upcoming wedding to a man she clearly does not love. This scene is repeated fifty years later when Lila comes and crawls into bed with her dying friend Ann to talk about the lives they have lived. In this latter scene, Streep and Redgrave are enthralling.<br /><br />The other memorable scene - at least to me - is when Buddy declares his love for Ann. Hugh Dancy as Buddy gives us a heartbreaking performance of a young man torn apart by his conflicting sexual feelings. His performance is superior.<br /><br />Chick flick? Yes. A very special film with unbelievable acting, directing, and scenery? Definitely. I cannot recommend Evening too much.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-e9H_CNX8O2",
        "colab_type": "code",
        "outputId": "6b6ee288-a93f-497f-ee73-d5a60700df46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "tokens_to_string(x_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"if you cannot enjoy a chick flick stop right now if however you enjoy films that illustrate complex characters and provide extraordinary acting read on br br ann grant lord is dying her two daughters arrive to be at her ann begins talking about people from her past of whom the daughters are unaware and they question as to whether these lost are real or imagined they come to realize that these people from their mother's past are indeed real br br the story shifts basically between 1953 and circa 2000 with a few glimpses at life between those years it was in 1953 that ann met the love of her life and experienced her life's greatest tragedy br br one of two best friends from college is being married other best friend is brother buddy and buddy are the children of a rich family whereas ann is a singer living in village who wants to be a free spirit but is still bound by many of those 1950's conventions br br soon after ann arrives to be maid of honor at wedding she meets the person who will become the pivotal character in the lives of the three harris he is the adult son of a former servant of the family who grew up with and buddy and has gone on to become a in a small new england town ann immediately becomes of harris which adds a to the fact that has always been in love with harris and continues to be buddy also is in love with harris but being 1953 he has that homosexual desire for harris to his good friend ann for he cannot admit to himself that he has a sexual for another man buddy his inner frustration by being the alcoholic wise cracking bad boy of the family much to the of his very proper and uptight parents br br needless to say all of these expressed and repressed emotions lead to tragedy after all this is a chick flick br br in the present time daughters have become distant from their mother and are suffering their own life and doubts is working to emotional trying to keep up her roll as perfect mother and wife nina having always felt inferior cannot maintain a relationship br br stir all of these relationships into a span of fifty years and you get an intriguing look at society its values and its effects upon the personalities and actions of the complex people involved br br all of the acting in evening is excellent but there are some extraordinary performances and scenes along with two unique family relationships that make this film so very very special br br claire danes plays the 1950's ann and she does it in a style that clearly shows an intelligent woman of those times who is conflicted by what she is supposed to do as opposed to what she wants to do her performance is not easily forgettable br br vanessa redgrave plays the dying ann whose mind shifts from the present to the past to of fantasy and of course redgrave pulls it all off with sterling style br br natasha richardson real daughter plays daughter in the film the scenes between this real life mother and daughter playing fictional mother and daughter are an insightful treat to watch br br toni plays other daughter nina nina spends a good deal of her time being depressed and feeling sorry for herself while out a good man who loves her as well as her mother and sister is perfect for a part such as this but i have never seen her give a bad or unbelievable performance no matter what part she plays br br plays 1950's and shows us a woman even more conflicted of her expected role in life than her good friend ann she is very good br br meryl streep mother plays present day what is there to say about meryl streep other than she always gives an insightful and rewarding performance br br director states in the dvd extras that he sought out glenn close to play the relatively small part of mother because he felt she was the only actress he could think of to play one scene in the film he certainly was right and performance in that one scene it in your mind all the other scenes in which close is very proper mother and you get another performance to treasure br br there are three other scenes in the film combined with the one featuring close described above that make the whole movie worth watching on wedding day ann comes into her room and into to bed with her friend to discuss about her upcoming wedding to a man she clearly does not love this scene is repeated fifty years later when comes and into bed with her dying friend ann to talk about the lives they have lived in this latter scene streep and redgrave are enthralling br br the other memorable scene at least to me is when buddy his love for ann hugh as buddy gives us a heartbreaking performance of a young man torn apart by his sexual feelings his performance is superior br br chick flick yes a very special film with unbelievable acting directing and scenery definitely i cannot recommend evening too much\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhBvz3EFX-aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X91-12ARYCie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMBwcy4hYFu2",
        "colab_type": "code",
        "outputId": "29c23b3e-9daf-41b7-b855-b9bc2bf8a8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 12:34:29.607911 140148265138048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAfhROjlYJvx",
        "colab_type": "code",
        "outputId": "46076547-e512-43a0-de50-4499befff4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.add(GRU(units=16, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 12:34:33.540786 140148265138048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o85eMPHYO9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(GRU(units=8, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzLXSZ8zYYLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(GRU(units=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gA3K4U6YaGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkTxp6_YfTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UC_Zry3YgjZ",
        "colab_type": "code",
        "outputId": "92e2887f-d915-4728-f573-28052c318c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 12:34:47.179125 140148265138048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg9gByRwYku3",
        "colab_type": "code",
        "outputId": "4f038b93-7c68-4021-d926-b4e97203458c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_embedding (Embedding)  (None, 544, 8)            80000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 544, 16)           1200      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 544, 8)            600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 81,961\n",
            "Trainable params: 81,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNERlTBYr_5",
        "colab_type": "code",
        "outputId": "9e5c084a-dd34-4345-817c-9f001d051875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "%%time\n",
        "model.fit(x_train_pad, y_train,\n",
        "          validation_split=0.05, epochs=4, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 23750 samples, validate on 1250 samples\n",
            "Epoch 1/4\n",
            "23750/23750 [==============================] - 276s 12ms/sample - loss: 0.5251 - acc: 0.7283 - val_loss: 0.4690 - val_acc: 0.8056\n",
            "Epoch 2/4\n",
            "23750/23750 [==============================] - 311s 13ms/sample - loss: 0.3038 - acc: 0.8843 - val_loss: 0.3908 - val_acc: 0.8320\n",
            "Epoch 3/4\n",
            "23750/23750 [==============================] - 311s 13ms/sample - loss: 0.2334 - acc: 0.9184 - val_loss: 0.3979 - val_acc: 0.8416\n",
            "Epoch 4/4\n",
            "23750/23750 [==============================] - 310s 13ms/sample - loss: 0.1942 - acc: 0.9347 - val_loss: 0.2887 - val_acc: 0.8944\n",
            "CPU times: user 35min 18s, sys: 2min 1s, total: 37min 20s\n",
            "Wall time: 20min 11s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7690591e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5w4FzgScOI_",
        "colab_type": "code",
        "outputId": "af5e2d64-f5e7-4f83-bed5-a30ed91fd3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "result = model.evaluate(x_test_pad, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 93s 4ms/sample - loss: 0.3608 - acc: 0.8572\n",
            "CPU times: user 1min 48s, sys: 1.64 s, total: 1min 49s\n",
            "Wall time: 1min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlRezmWkcq2V",
        "colab_type": "code",
        "outputId": "1e4e85ba-3a3e-4b13-fe59-dce7d5211792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IClF_Tcy-l",
        "colab_type": "code",
        "outputId": "e7c0d51f-0639-4ac5-b5eb-872131bb79e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "%%time\n",
        "y_pred = model.predict(x=x_test_pad[0:1000])\n",
        "y_pred = y_pred.T[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6cad20b5af74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_pred = model.predict(x=x_test_pad[0:1000])\\ny_pred = y_pred.T[0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APetRl_sc8FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Lz7LOodAcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_true = np.array(y_test[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEDNyGS9dDoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incorrect = np.where(cls_pred != cls_true)\n",
        "incorrect = incorrect[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQKcThxMdHJQ",
        "colab_type": "code",
        "outputId": "651c962d-b00f-46f8-e786-ff2a0e03532b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(incorrect)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-wt9-YdKQ_",
        "colab_type": "code",
        "outputId": "3d081935-4ce1-4fc1-b14e-abb8ab961fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "idx = incorrect[0]\n",
        "idx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnqg2CUTdLkA",
        "colab_type": "code",
        "outputId": "450b6162-fc6f-4a4c-a27d-cf2c68aeab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "text = x_test_text[idx]\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I SELL THE DEAD (2009) **1/2 Dominic Monaghan, Larry Fessenden, Ron Perlman, Angus Scrimm, John Speredakos, Eileen Colgan, Brenda Cooney. Uneven blend of horror and comedy that poses as a valentine to the '60s horror films by Roger Corman and Hammer Studios, with two cretinous grave robbers (Monaghan and Fessenden) facing final punishments for the crimes via the guillotine but not before their tales of the occult can be recalled in flashbacks. Amusing and a few well sprinkled jolts but really a mess of a B-movie trying in vein to be a cult classic largely thanks to the casting of genre vets Perlman and Scrimm to no avail; a good rental for Halloween. (Dir: Glenn McQuaid)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srSgSdsqdTe9",
        "colab_type": "code",
        "outputId": "65aeb30d-d908-40d0-d65a-3b000c3cb3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_pred[idx]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.037938207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bix1oGsdU3-",
        "colab_type": "code",
        "outputId": "6277d206-49ca-43d2-e56d-7f741fc15fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cls_true[idx]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSesar2PdYWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
        "text2 = \"Good movie!\"\n",
        "text3 = \"Maybe I like this movie.\"\n",
        "text4 = \"Meh ...\"\n",
        "text5 = \"If I were a drunk teenager then this movie might be good.\"\n",
        "text6 = \"Bad movie!\"\n",
        "text7 = \"Not a good movie!\"\n",
        "text8 = \"This movie really sucks! Can I get my money back please?\"\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I22XRhQUddNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfoeDJ1mdjMA",
        "colab_type": "code",
        "outputId": "83d4847c-be7a-40db-fb80-8806c2de6396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)\n",
        "tokens_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uchPXJw9dovJ",
        "colab_type": "code",
        "outputId": "125f6e36-0424-4035-e219-f0b510d2182a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96067977],\n",
              "       [0.89856577],\n",
              "       [0.75594366],\n",
              "       [0.84377855],\n",
              "       [0.67702633],\n",
              "       [0.42514688],\n",
              "       [0.8552542 ],\n",
              "       [0.25050125]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlPUAlGmdqet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_embedding = model.get_layer('layer_embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i76V9ILwdwh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_embedding = layer_embedding.get_weights()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BngERaPvdyzz",
        "colab_type": "code",
        "outputId": "61cb39e5-a6ab-4995-88d9-3f17fc83ff41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "weights_embedding.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0VFuC5Od2OL",
        "colab_type": "code",
        "outputId": "59f54cd7-7cd6-483c-bac0-4abb53eec0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "token_good = tokenizer.word_index['good']\n",
        "token_good"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN7AQb6Kd39I",
        "colab_type": "code",
        "outputId": "8be63d59-4bbf-4a02-b67b-85c327bc3f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "token_great = tokenizer.word_index['great']\n",
        "token_great"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcE9ujAXeAld",
        "colab_type": "code",
        "outputId": "8d069a59-1224-4c34-ce8b-217376160808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weights_embedding[token_good]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.06990868, -0.0635757 ,  0.00651114,  0.02910687,  0.02221848,\n",
              "       -0.08204393, -0.04282869,  0.00865578], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vusg1zw1eB50",
        "colab_type": "code",
        "outputId": "3bbc4578-79dc-4836-98e9-14fd81a8d228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weights_embedding[token_great]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.10235833, -0.1256574 ,  0.16474661,  0.11950813,  0.10953443,\n",
              "       -0.15126067, -0.13183455,  0.12016096], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP9ZbRSYeGsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_bad = tokenizer.word_index['bad']\n",
        "token_horrible = tokenizer.word_index['horrible']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgb7wYkBePOD",
        "colab_type": "code",
        "outputId": "8d7b2845-72d4-4d9f-a15c-4273e81542b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weights_embedding[token_bad]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.15679997,  0.09429009, -0.13303772, -0.08758956, -0.06235645,\n",
              "        0.08507401,  0.08585963, -0.1390407 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYqZPThUeQon",
        "colab_type": "code",
        "outputId": "f7a78b67-866a-4d75-cd72-0a854e5c405b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "weights_embedding[token_horrible]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.14237069,  0.20652135, -0.12281132, -0.1362023 , -0.16818562,\n",
              "        0.17382565,  0.1984778 , -0.20665692], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKryzmKieYZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_sorted_words(word, metric='cosine'):\n",
        "    \"\"\"\n",
        "    Print the words in the vocabulary sorted according to their\n",
        "    embedding-distance to the given word.\n",
        "    Different metrics can be used, e.g. 'cosine' or 'euclidean'.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the token (i.e. integer ID) for the given word.\n",
        "    token = tokenizer.word_index[word]\n",
        "\n",
        "    # Get the embedding for the given word. Note that the\n",
        "    # embedding-weight-matrix is indexed by the word-tokens\n",
        "    # which are integer IDs.\n",
        "    embedding = weights_embedding[token]\n",
        "\n",
        "    # Calculate the distance between the embeddings for\n",
        "    # this word and all other words in the vocabulary.\n",
        "    distances = cdist(weights_embedding, [embedding],\n",
        "                      metric=metric).T[0]\n",
        "    \n",
        "    # Get an index sorted according to the embedding-distances.\n",
        "    # These are the tokens (integer IDs) for words in the vocabulary.\n",
        "    sorted_index = np.argsort(distances)\n",
        "    \n",
        "    # Sort the embedding-distances.\n",
        "    sorted_distances = distances[sorted_index]\n",
        "    \n",
        "    # Sort all the words in the vocabulary according to their\n",
        "    # embedding-distance. This is a bit excessive because we\n",
        "    # will only print the top and bottom words.\n",
        "    sorted_words = [inverse_map[token] for token in sorted_index\n",
        "                    if token != 0]\n",
        "\n",
        "    # Helper-function for printing words and embedding-distances.\n",
        "    def _print_words(words, distances):\n",
        "        for word, distance in zip(words, distances):\n",
        "            print(\"{0:.3f} - {1}\".format(distance, word))\n",
        "\n",
        "    # Number of words to print from the top and bottom of the list.\n",
        "    k = 10\n",
        "\n",
        "    print(\"Distance from '{0}':\".format(word))\n",
        "\n",
        "    # Print the words with smallest embedding-distance.\n",
        "    _print_words(sorted_words[0:k], sorted_distances[0:k])\n",
        "\n",
        "    print(\"...\")\n",
        "\n",
        "    # Print the words with highest embedding-distance.\n",
        "    _print_words(sorted_words[-k:], sorted_distances[-k:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIDLoVTweame",
        "colab_type": "code",
        "outputId": "8f1381bd-fd1f-4539-f1f2-52bedc155077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "print_sorted_words('great', metric='cosine')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-057bc44af0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_sorted_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'great'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'print_sorted_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQcmFPpPeiAP",
        "colab_type": "code",
        "outputId": "5203f0d3-05db-463b-b6ef-4b51bd7634ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "print_sorted_words('worst', metric='cosine')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance from 'worst':\n",
            "0.000 - worst\n",
            "0.005 - stupidity\n",
            "0.005 - boredom\n",
            "0.005 - wasting\n",
            "0.005 - annoying\n",
            "0.005 - baldwin\n",
            "0.006 - moronic\n",
            "0.006 - conflict\n",
            "0.006 - habits\n",
            "0.006 - christians\n",
            "...\n",
            "1.992 - stress\n",
            "1.992 - kubrick\n",
            "1.992 - both\n",
            "1.993 - adored\n",
            "1.993 - realistic\n",
            "1.993 - 8\n",
            "1.995 - helps\n",
            "1.995 - safety\n",
            "1.995 - refreshing\n",
            "1.997 - fortunate\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}